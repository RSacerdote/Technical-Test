{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "import pandas as pd\n",
    "from snowflake.connector import connect, ProgrammingError\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "import names\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_path = './data') -> tuple[pd.DataFrame, pd.DataFrame, dict[str, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Load transaction, customer and name data.\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str, optional): Path to the stored data. Defaults to './data'\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the transactions dataframe, the customers dataframe and the reference names dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    # Reading data from csv\n",
    "    transactions = pd.read_csv(f'{csv_path}/transactions.csv')\n",
    "    customers = pd.read_csv(f'{csv_path}/customers.csv')\n",
    "\n",
    "    # Getting most common names from the US Census (public data)\n",
    "    # It is fetched through the module \"names\" and stored in the package data\n",
    "    reference_names = {}\n",
    "    for key, path in names.FILES.items():\n",
    "        column_names = ['name', 'pct', 'sum_pct', 'position']\n",
    "\n",
    "        df = pd.read_csv(\n",
    "            path,\n",
    "            sep=r'\\s+',\n",
    "            names=column_names, \n",
    "            nrows=1000,\n",
    "        )\n",
    "        reference_names[key] = df\n",
    "    \n",
    "    return transactions, customers, reference_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_score(name: str, choices: list[str]) -> int:\n",
    "    \"\"\"\n",
    "    Find the best score for a match between the name and the choices.\n",
    "\n",
    "    Args:\n",
    "        name (str): The name to be matched against the choices.\n",
    "        choices (list[str]): A list with the possible choices to match the name to.\n",
    "\n",
    "    Returns:\n",
    "        int: The biggest score.\n",
    "    \"\"\"\n",
    "    best, score = process.extractOne(name, choices, scorer=fuzz.token_set_ratio)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_best(name: str, choices: list[str], threshold: int = 75) -> str | None:\n",
    "    \"\"\"\n",
    "    Wrapper for the extractOne function which allows it to be called from apply.\n",
    "    \n",
    "    Args:\n",
    "        name (str): The name to be matched against the choices.\n",
    "        choices (list[str]): A list with the possible choices to match the name to.\n",
    "        threshold (int, optional): The threshold to filter the results by (inclusive).\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The best match, if there's one with score bigger than the threshold.\n",
    "    \"\"\"\n",
    "    result = process.extractOne(name, choices, scorer=fuzz.token_set_ratio, score_cutoff=threshold)\n",
    "    if result is not None:\n",
    "        return result[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_full_name(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Find the most probable full name using the scores columns.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A pandas Series with the columns customer_name_1, customer_name_2, score_1, score_2, score_last_1, score_last_2.\n",
    "\n",
    "    Returns:\n",
    "        str: The most probable full name.\n",
    "    \"\"\"\n",
    "    if row['score_1'] > row['score_2']:\n",
    "        best_first = row['customer_name_1'].split(' ')[0]\n",
    "    elif row['score_2'] > row['score_1']:\n",
    "        best_first = row['customer_name_2'].split(' ')[0]\n",
    "    else:\n",
    "        best_first = row['customer_name_1'].split(' ')[0]\n",
    "\n",
    "    if row['score_last_1'] > row['score_last_2']:\n",
    "        best_last = row['customer_name_1'].split(' ')[1]\n",
    "    elif row['score_last_2'] > row['score_last_1']:\n",
    "        best_last = row['customer_name_2'].split(' ')[1]\n",
    "    else:\n",
    "        best_last = row['customer_name_1'].split(' ')[1]\n",
    "\n",
    "    return f\"{best_first} {best_last}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_snowflake(verbose: bool =True):\n",
    "    \"\"\"\n",
    "    Uses environment variables to connect to Snowflake.\n",
    "    \n",
    "    Args:\n",
    "        verbose (bool, optional): Set to true to display more information about the connection atempt. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        Optional[SnowflakeConnection]: The connection to the snowflake database.\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "\n",
    "    SNOWFLAKE_ACCOUNT = os.getenv('SNOWFLAKE_ACCOUNT')\n",
    "    SNOWFLAKE_USER = os.getenv('SNOWFLAKE_USER')\n",
    "    SNOWFLAKE_PASSWORD = os.getenv('SNOWFLAKE_PASSWORD')\n",
    "    SNOWFLAKE_WAREHOUSE = os.getenv('SNOWFLAKE_WAREHOUSE')\n",
    "    SNOWFLAKE_DATABASE = os.getenv('SNOWFLAKE_DATABASE')\n",
    "    SNOWFLAKE_SCHEMA = os.getenv('SNOWFLAKE_SCHEMA')\n",
    "\n",
    "    try:\n",
    "        conn = connect(\n",
    "            user=SNOWFLAKE_USER,\n",
    "            password=SNOWFLAKE_PASSWORD,\n",
    "            account=SNOWFLAKE_ACCOUNT,\n",
    "            warehouse=SNOWFLAKE_WAREHOUSE,\n",
    "            database=SNOWFLAKE_DATABASE,\n",
    "            schema=SNOWFLAKE_SCHEMA\n",
    "        )\n",
    "        if verbose:\n",
    "            print(\"Connection to Snowflake established successfully.\")\n",
    "        return conn\n",
    "    except ProgrammingError as e:\n",
    "        if verbose:\n",
    "            print(f\"Error connecting to Snowflake: {e}\")  \n",
    "    return None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(conn, table_name: str, verbose: str = False) -> bool:\n",
    "    \"\"\"\n",
    "    Creates a table in the connected Snowflake database.\n",
    "\n",
    "    Args:\n",
    "        conn: The Snowflake connection object.\n",
    "        table_name (str): The name of the table to create.\n",
    "        verbose (bool, optional): Set to true to display more information about the execution. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the table was created successfully, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            create_table_query = f\"\"\"\n",
    "            CREATE OR REPLACE TABLE {table_name} (\n",
    "                transaction_id INTEGER,\n",
    "                amount INTEGER,\n",
    "                transaction_date DATE,\n",
    "                customer_id INTEGER,\n",
    "                email STRING,\n",
    "                customer_name STRING\n",
    "            )\n",
    "            \"\"\"\n",
    "            cursor.execute(create_table_query)\n",
    "            if verbose:\n",
    "                print(f\"Table '{table_name}' created successfully.\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Failed to create table '{table_name}': {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to Snowflake established successfully.\n",
      "Successfully uploaded 10 rows to CUSTOMER_TRANSACTIONS in 1 chunks.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Loading data from csv and module files\n",
    "    transactions, customers, reference_names = load_data()\n",
    "\n",
    "    # Matching the customer_names from both dataframes using fuzzy matching\n",
    "    customers_names = customers['customer_name'].tolist()\n",
    "    transactions['external_name'] = transactions['customer_name'].apply(lambda name: extract_best(name, customers_names))\n",
    "\n",
    "    # Merging the two dataframes\n",
    "    merged_df = pd.merge(\n",
    "        transactions,\n",
    "        customers,\n",
    "        left_on='external_name',\n",
    "        right_on='customer_name',\n",
    "        how='left',\n",
    "        suffixes=('_1', '_2')\n",
    "    )\n",
    "\n",
    "    # Turning any None (in this case it would be a transaction without a matching customer name) into \" \" so that it can be parsed by the next step\n",
    "    merged_df = merged_df.fillna(' ')\n",
    "\n",
    "    # Removing duplicate column\n",
    "    merged_df.drop(columns=['external_name'], inplace=True)\n",
    "\n",
    "    # Scoring the names based on the reference list to get the most probable full name\n",
    "    merged_df['score_1'] = merged_df['customer_name_1'].apply(lambda name: get_best_score(name.split(' ')[0], reference_names['first:female']['name'].to_list()+reference_names['first:male']['name'].to_list()))\n",
    "    merged_df['score_2'] = merged_df['customer_name_2'].apply(lambda name: get_best_score(name.split(' ')[0], reference_names['first:female']['name'].to_list()+reference_names['first:male']['name'].to_list()))\n",
    "    merged_df['score_last_1'] = merged_df['customer_name_1'].apply(lambda name: get_best_score(name.split(' ')[1], reference_names['last']['name'].to_list()))\n",
    "    merged_df['score_last_2'] = merged_df['customer_name_2'].apply(lambda name: get_best_score(name.split(' ')[1], reference_names['last']['name'].to_list()))\n",
    "    merged_df['customer_name'] = merged_df.apply(lambda row: select_best_full_name(row), axis=1)\n",
    "    merged_df.drop(columns=['customer_name_1', 'customer_name_2', 'score_1', 'score_2', 'score_last_1', 'score_last_2'], inplace=True)\n",
    "\n",
    "    # Preparing the column names to allow it to be uploaded to snowflake\n",
    "    merged_df.columns = [str.upper(column_name) for column_name in merged_df.columns]\n",
    "\n",
    "    # Connecting to snowflake using the environment variables\n",
    "    conn = connect_to_snowflake()\n",
    "\n",
    "    # Creating a new table (or replacing an existing one)\n",
    "    table_name = 'CUSTOMER_TRANSACTIONS'\n",
    "    create_table(conn, table_name)\n",
    "\n",
    "    # Uploading data to the new table on snowflake\n",
    "    success, nchunks, nrows, _ = write_pandas(conn, merged_df, table_name)\n",
    "    if success:\n",
    "        print(f\"Successfully uploaded {nrows} rows to {table_name} in {nchunks} chunks.\")\n",
    "    else:\n",
    "        print(\"Failed to upload DataFrame to Snowflake.\")\n",
    "\n",
    "    # Closing the connection\n",
    "    conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
